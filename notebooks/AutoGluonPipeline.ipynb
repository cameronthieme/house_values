{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539e84fa-b49b-4b0b-bcc9-b12a71c1af8f",
   "metadata": {},
   "source": [
    "# Auto ML Pipeline\n",
    "Using AutoGluon for prediction with a little bit of pre-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9767d03d-fc9b-41e3-8deb-9b82821f8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77561710-be9a-4235-92b9-22afd8e08f47",
   "metadata": {},
   "source": [
    "## Format Data\n",
    "\n",
    "Read data and do basic cleaning of NaN values\n",
    "\n",
    "We will only replace values if there is a meaningful replacement; otherwise we leave it for AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e38005-f3ba-44a1-855c-f41abf31fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and convert target variable to log\n",
    "# log conversion normalizes data (also is where we measure RMSE)\n",
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_train['SalePrice']= np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a527f51-519b-48bd-a97a-14a253d3eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "                   \n",
      "that is 19 columns\n",
      "NaN Value Counts in Each Column:\n",
      "Id                 0\n",
      "MSSubClass         0\n",
      "MSZoning           0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "                ... \n",
      "MoSold             0\n",
      "YrSold             0\n",
      "SaleType           0\n",
      "SaleCondition      0\n",
      "SalePrice          0\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find columns containing NaN values\n",
    "columns_with_nan = df_train.columns[df_train.isna().any()].tolist()\n",
    "\n",
    "# Print the columns with NaN values\n",
    "print(\"Columns with NaN values:\", columns_with_nan)\n",
    "print('                   ')\n",
    "print('that is ' + str(len(columns_with_nan)) + ' columns')\n",
    "\n",
    "# Count NaN values in each column\n",
    "nan_counts = df_train.isna().sum()\n",
    "\n",
    "# Print the counts of NaN values in each column\n",
    "print(\"NaN Value Counts in Each Column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea68336-af72-4a5d-9353-a835d7c1b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several features seem really easily fillable\n",
    "# Categoricals that seem to be NaN because that feature is not on property\n",
    "# often are other columns that verify this assumption (such as area = 0)\n",
    "\n",
    "easy_fix_cols = ['Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',  'BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "\n",
    "# Replace NaN values in the categorical column with 'noFeature'\n",
    "replacement_value = 'noFeature'\n",
    "for col in easy_fix_cols:\n",
    "    df_train[col] = df_train[col].fillna(replacement_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc1f74d-acbc-4195-9ff0-ff66a9675efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values in 'MasVnrArea' are because there is no masonry veneer\n",
    "\n",
    "# Find the indices of NaN entries in the 'MasVnrArea' column\n",
    "column_name = 'MasVnrArea'\n",
    "nan_indices = df_train[df_train[column_name].isna()].index\n",
    "\n",
    "# Set the values in the 'MasVnrArea' column for the specified indices to 0\n",
    "df_train.loc[nan_indices, column_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22766054-0949-445e-a53c-6044b2019c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume missing 'LotFrontage' Values have no lot frontage\n",
    "df_train['LotFrontage'] = df_train['LotFrontage'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678979f3-6d63-4bf2-91ab-5362fcebb6fa",
   "metadata": {},
   "source": [
    "### things we won't fix\n",
    "\n",
    "We will leave missing garage built year empty because there is no obvious meaningful way to replace it, might as well leave to Autogluon\n",
    "\n",
    "There is one empty 'Electrical' variable, also leave that to Autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e631214-856d-499c-a811-743827dc22c8",
   "metadata": {},
   "source": [
    "## Autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f8fdf-2509-4986-a48d-38482de55c09",
   "metadata": {},
   "source": [
    "### CV\n",
    "\n",
    "Check and see if we can get an idea of performance from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675469d9-ecf9-4b22-9c38-461f6ce2b522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194312/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194312/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   19.28 GB / 250.69 GB (7.7%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02686, 0.4017)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2702.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t1.3s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/Users/cameronthieme/house_env/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "\t-0.2436\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2418\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1376\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1398\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1564\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1347\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.74s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1493\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.141\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.63s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1379\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1327\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.42s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.14704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.147\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.89s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1276\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 55.31s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194312/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194408/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194408/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   19.20 GB / 250.69 GB (7.7%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.01889, 0.39994)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2820.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.54s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2412\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2387\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1354\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1405\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1532\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.131\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.15s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1461\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1386\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.79s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.143\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.56s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1367\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.93s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1508\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1269\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.22s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194408/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194508/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194508/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   19.14 GB / 250.69 GB (7.6%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02367, 0.39657)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2636.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t2.4s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2351\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2322\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.136\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1383\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1522\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1302\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1446\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1339\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1464\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1304\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1499\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1246\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 47.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194508/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194556/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194556/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   19.08 GB / 250.69 GB (7.6%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.47194980911048, 12.02375, 0.39642)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2745.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.4s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2308\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2268\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1293\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1351\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1408\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1231\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1386\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t-0.1254\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.67s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1312\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.123\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.04s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1352\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1167\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 67.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194556/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194704/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194704/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   19.02 GB / 250.69 GB (7.6%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.521139497361697, 10.460242108190519, 12.02377, 0.39287)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2663.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.54s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2327\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2288\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1145\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1177\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1223\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1128\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.97s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1252\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1067\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.08s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.12\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1111\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.38s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1273\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.79s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.101\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 47.8s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194704/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194752/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194752/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.96 GB / 250.69 GB (7.6%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02138, 0.4036)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2709.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.6s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.63s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2282\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.225\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1181\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1253\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1112\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1266\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.114\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.126\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1073\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.17s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1269\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.54s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1024\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 65.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194752/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194858/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194858/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.92 GB / 250.69 GB (7.5%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02793, 0.4005)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2671.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Utilities']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 42 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['Street', 'CentralAir']\n",
      "\t0.6s = Fit runtime\n",
      "\t79 features in original data used to generate 79 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.66s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2241\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2206\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1072\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1099\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1197\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1082\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.71s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1141\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1029\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1098\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0975\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1259\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.092\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 35.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194858/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_194933/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_194933/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.87 GB / 250.69 GB (7.5%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02808, 0.40213)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2696.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.56s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2257\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2225\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1143\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1171\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1225\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1074\t = Validation score   (-root_mean_squared_error)\n",
      "\t287.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1241\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1134\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1194\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1093\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.53s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1258\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.7s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.101\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 309.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_194933/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_195443/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_195443/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.79 GB / 250.69 GB (7.5%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.01906, 0.40162)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2585.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.56s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2223\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2191\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1182\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.118\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1234\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1077\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.123\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1101\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1142\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.71s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1084\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.02s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1264\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1006\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 44.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_195443/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_195528/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_195528/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.73 GB / 250.69 GB (7.5%)\n",
      "Train Data Rows:    1314\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02713, 0.39905)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2624.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.85 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.5s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1051, Val Rows: 263\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2233\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2203\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1246\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1287\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1342\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.115\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.89s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1294\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1363\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1119\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1412\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.62s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.136732\n",
      "[2000]\tvalid_set's rmse: 0.136671\n",
      "[3000]\tvalid_set's rmse: 0.136669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1367\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.66s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1082\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 86.41s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_195528/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean is -0.12087880090216571\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Calculate the number of samples and the size of each fold\n",
    "num_samples = len(df_train)\n",
    "fold_size = num_samples // num_folds\n",
    "\n",
    "# Initialize lists to store the train and test data\n",
    "rmse_list = []\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold in range(num_folds):\n",
    "    # Calculate the start and end indices for the test set\n",
    "    start = fold * fold_size\n",
    "    end = (fold + 1) * fold_size if fold < num_folds - 1 else num_samples\n",
    "\n",
    "    # Use the current fold for testing and the rest for training\n",
    "    tempTest = df_train.iloc[start:end, :]  # Slice the DataFrame\n",
    "    tempTrain = pd.concat([df_train.iloc[:start, :], df_train.iloc[end:, :]])  # Concatenate DataFrames\n",
    "\n",
    "    # convert to Tabular Datasets\n",
    "    tempTest = TabularDataset(tempTest)\n",
    "    tempTrain = TabularDataset(tempTrain)\n",
    "\n",
    "    # fit predictor\n",
    "    tempPredictor = TabularPredictor(label='SalePrice').fit(tempTrain)\n",
    "\n",
    "    # find RMSE of logs\n",
    "    rmse = tempPredictor.evaluate(tempTest, silent=True)['root_mean_squared_error']\n",
    "    \n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# find CV mean of rmse\n",
    "print('CV mean is ' + str(sum(rmse_list) / len(rmse_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8f53db-868e-4838-8525-9cb47f2fa2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11477600584917631,\n",
       " -0.09665098761177439,\n",
       " -0.10251422370823247,\n",
       " -0.15676306688418543,\n",
       " -0.14315737231602807,\n",
       " -0.09812600747053027,\n",
       " -0.12014073494694316,\n",
       " -0.100005239753442,\n",
       " -0.13929900121853114,\n",
       " -0.13735536926281383]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d31aa-d0b7-45ee-87b0-0a8dd4fe708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_train = TabularDataset(df_train)\n",
    "\n",
    "predictor = TabularPredictor(td_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house_env",
   "language": "python",
   "name": "house_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
