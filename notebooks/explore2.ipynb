{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a399cb-e0ca-4256-8884-3d329de50f7c",
   "metadata": {},
   "source": [
    "# House Prices Initial Exploration\n",
    "\n",
    "I have switched to a second notebook since the first got really messy\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c49f85f-ae47-4c26-bbd9-1054375f1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839af3c-cc41-4b6c-ae25-ccf935400855",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1f0120-dfc4-47ca-b7bc-e3220fe9874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985d02cc-47e5-4171-9074-e4d00768c547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55a0d3-b3bb-4dd8-a59d-afc5f6c2bcf1",
   "metadata": {},
   "source": [
    "## Some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51eb07f-0871-4a86-894e-f31004374763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change number of rows/columns we will view\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42100622-8a12-4fd0-98f6-caeb070fb9c3",
   "metadata": {},
   "source": [
    "## Going Log\n",
    "\n",
    "Since the goal is to predict the log of sales price, let's convert that right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25f6f4a-2169-4a55-bc65-e433deb05cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['LogSalePrice']= np.log(df_train['SalePrice'])\n",
    "df_train['SalePrice']= np.log(df_train['SalePrice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05c0ac-5f82-4668-8b2c-8d6542fcc3b4",
   "metadata": {},
   "source": [
    "# Find the NaN\n",
    "\n",
    "Fix NaN values early\n",
    "\n",
    "Dataset is clean so this is fairly easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa32e48a-0bcd-42fb-b4f4-4998c7ac88e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "                   \n",
      "that is 19 columns\n",
      "NaN Value Counts in Each Column:\n",
      "Id                 0\n",
      "MSSubClass         0\n",
      "MSZoning           0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "                ... \n",
      "MoSold             0\n",
      "YrSold             0\n",
      "SaleType           0\n",
      "SaleCondition      0\n",
      "SalePrice          0\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find columns containing NaN values\n",
    "columns_with_nan = df_train.columns[df_train.isna().any()].tolist()\n",
    "\n",
    "# Print the columns with NaN values\n",
    "print(\"Columns with NaN values:\", columns_with_nan)\n",
    "print('                   ')\n",
    "print('that is ' + str(len(columns_with_nan)) + ' columns')\n",
    "\n",
    "# Count NaN values in each column\n",
    "nan_counts = df_train.isna().sum()\n",
    "\n",
    "# Print the counts of NaN values in each column\n",
    "print(\"NaN Value Counts in Each Column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1d374e-56b3-4d3f-9cda-129a62964a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0     143\n",
      "70.0      70\n",
      "80.0      69\n",
      "50.0      57\n",
      "75.0      53\n",
      "        ... \n",
      "137.0      1\n",
      "141.0      1\n",
      "38.0       1\n",
      "140.0      1\n",
      "46.0       1\n",
      "Name: LotFrontage, Length: 110, dtype: int64\n",
      "Grvl    50\n",
      "Pave    41\n",
      "Name: Alley, dtype: int64\n",
      "None       864\n",
      "BrkFace    445\n",
      "Stone      128\n",
      "BrkCmn      15\n",
      "Name: MasVnrType, dtype: int64\n",
      "0.0      861\n",
      "180.0      8\n",
      "72.0       8\n",
      "108.0      8\n",
      "120.0      7\n",
      "        ... \n",
      "562.0      1\n",
      "89.0       1\n",
      "921.0      1\n",
      "762.0      1\n",
      "119.0      1\n",
      "Name: MasVnrArea, Length: 327, dtype: int64\n",
      "TA    649\n",
      "Gd    618\n",
      "Ex    121\n",
      "Fa     35\n",
      "Name: BsmtQual, dtype: int64\n",
      "TA    1311\n",
      "Gd      65\n",
      "Fa      45\n",
      "Po       2\n",
      "Name: BsmtCond, dtype: int64\n",
      "No    953\n",
      "Av    221\n",
      "Gd    134\n",
      "Mn    114\n",
      "Name: BsmtExposure, dtype: int64\n",
      "Unf    430\n",
      "GLQ    418\n",
      "ALQ    220\n",
      "BLQ    148\n",
      "Rec    133\n",
      "LwQ     74\n",
      "Name: BsmtFinType1, dtype: int64\n",
      "Unf    1256\n",
      "Rec      54\n",
      "LwQ      46\n",
      "BLQ      33\n",
      "ALQ      19\n",
      "GLQ      14\n",
      "Name: BsmtFinType2, dtype: int64\n",
      "SBrkr    1334\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n",
      "Gd    380\n",
      "TA    313\n",
      "Fa     33\n",
      "Ex     24\n",
      "Po     20\n",
      "Name: FireplaceQu, dtype: int64\n",
      "Attchd     870\n",
      "Detchd     387\n",
      "BuiltIn     88\n",
      "Basment     19\n",
      "CarPort      9\n",
      "2Types       6\n",
      "Name: GarageType, dtype: int64\n",
      "2005.0    65\n",
      "2006.0    59\n",
      "2004.0    53\n",
      "2003.0    50\n",
      "2007.0    49\n",
      "          ..\n",
      "1927.0     1\n",
      "1900.0     1\n",
      "1906.0     1\n",
      "1908.0     1\n",
      "1933.0     1\n",
      "Name: GarageYrBlt, Length: 97, dtype: int64\n",
      "Unf    605\n",
      "RFn    422\n",
      "Fin    352\n",
      "Name: GarageFinish, dtype: int64\n",
      "TA    1311\n",
      "Fa      48\n",
      "Gd      14\n",
      "Ex       3\n",
      "Po       3\n",
      "Name: GarageQual, dtype: int64\n",
      "TA    1326\n",
      "Fa      35\n",
      "Gd       9\n",
      "Po       7\n",
      "Ex       2\n",
      "Name: GarageCond, dtype: int64\n",
      "Gd    3\n",
      "Ex    2\n",
      "Fa    2\n",
      "Name: PoolQC, dtype: int64\n",
      "MnPrv    157\n",
      "GdPrv     59\n",
      "GdWo      54\n",
      "MnWw      11\n",
      "Name: Fence, dtype: int64\n",
      "Shed    49\n",
      "Gar2     2\n",
      "Othr     2\n",
      "TenC     1\n",
      "Name: MiscFeature, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in columns_with_nan:\n",
    "    print(df_train[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c81180-a513-4d33-aa3a-ddc7d755f654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      81\n",
       "440    49\n",
       "576    47\n",
       "240    38\n",
       "484    34\n",
       "       ..\n",
       "320     1\n",
       "594     1\n",
       "831     1\n",
       "878     1\n",
       "192     1\n",
       "Name: GarageArea, Length: 441, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['GarageArea'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea392671-25ca-4945-8e42-17cbd7d9270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several features seem really easily fillable\n",
    "# Categoricals that seem to be NaN because that feature is not on property\n",
    "# often are other columns that verify this assumption (such as area = 0)\n",
    "\n",
    "easy_fix_cols = ['Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',  'BsmtFinType2', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "\n",
    "# Replace NaN values in the categorical column with 'noFeature'\n",
    "replacement_value = 'noFeature'\n",
    "for col in easy_fix_cols:\n",
    "    df_train[col] = df_train[col].fillna(replacement_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d947147-7723-4067-81bc-bf4ea796fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in the 'MasVnrType' column for the specified indices:\n",
      "234     noFeature\n",
      "529     noFeature\n",
      "650     noFeature\n",
      "936     noFeature\n",
      "973     noFeature\n",
      "977     noFeature\n",
      "1243    noFeature\n",
      "1278    noFeature\n",
      "Name: MasVnrType, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# MasVnrArea has some weird missing values\n",
    "\n",
    "# Find the indices of NaN entries in the 'MasVnrArea' column\n",
    "column_name = 'MasVnrArea'\n",
    "nan_indices = df_train[df_train[column_name].isna()].index\n",
    "\n",
    "# Print the values in the 'MasVnrType' column for the specified indices\n",
    "column_name = 'MasVnrType'\n",
    "values_for_indices = df_train.loc[nan_indices, column_name]\n",
    "print(\"Values in the 'MasVnrType' column for the specified indices:\")\n",
    "print(values_for_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0c3ec-95b7-4aa5-a696-0f6d53b36bae",
   "metadata": {},
   "source": [
    "From above, we see that all missing values of MasVnrArea are in houses with no masonry veneer.  So we can safely make them 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79dc340c-df01-4bcd-8807-ab2488a78543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values in the 'MasVnrArea' column for the specified indices to 0\n",
    "column_name = 'MasVnrArea'\n",
    "df_train.loc[nan_indices, column_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d0ed50-00cc-4010-ad3e-c366aff12d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['LotFrontage', 'Electrical', 'GarageYrBlt']\n",
      "                   \n",
      "that is 3 columns\n"
     ]
    }
   ],
   "source": [
    "# now check that the replacements worked\n",
    "\n",
    "# Find columns containing NaN values\n",
    "columns_with_nan = df_train.columns[df_train.isna().any()].tolist()\n",
    "\n",
    "# Print the columns with NaN values\n",
    "print(\"Columns with NaN values:\", columns_with_nan)\n",
    "print('                   ')\n",
    "print('that is ' + str(len(columns_with_nan)) + ' columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0b825-e61c-48ac-a513-ad1e282c97c6",
   "metadata": {},
   "source": [
    "## weirdest NaN\n",
    "\n",
    "There are 3 remaining features with NaN values: LotFrontage, Electrical, and GarageYrBlt\n",
    "\n",
    "Missing LotFrontage is either because lot has no connection to street, or measurement wasn't take.  We will assume the former and replace LotFrontage missing values with 0.\n",
    "\n",
    "Will replace Electrical missing value (it's only one) with most common value\n",
    "\n",
    "Will drop GarageYrBlt for now because idk what to replace that value with (it's where there is no garage); I think this should be okay because there is big correlation with Year built and the other garage variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54312923-f2d0-444e-9397-aee3dc38c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanLotFrontage = df_train['LotFrontage'].mean()\n",
    "# df_train['LotFrontage'] = df_train['LotFrontage'].fillna(meanLotFrontage)\n",
    "df_train['LotFrontage'] = df_train['LotFrontage'].fillna(0)\n",
    "\n",
    "most_common_value = df_train['Electrical'].value_counts().idxmax()\n",
    "df_train['Electrical'] = df_train['Electrical'].fillna(most_common_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314e5a87-c8c5-4c0e-aa57-31ebd4000c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values: ['GarageYrBlt']\n",
      "                   \n",
      "that is 1 columns\n"
     ]
    }
   ],
   "source": [
    "# now check that the replacements worked\n",
    "\n",
    "# Find columns containing NaN values\n",
    "columns_with_nan = df_train.columns[df_train.isna().any()].tolist()\n",
    "\n",
    "# Print the columns with NaN values\n",
    "print(\"Columns with NaN values:\", columns_with_nan)\n",
    "print('                   ')\n",
    "print('that is ' + str(len(columns_with_nan)) + ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e158f4-1def-495b-81e9-68a5c6fe494d",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "\n",
    "Begin by throwing everything at the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e31b8-4675-49ec-b9b0-1a6c5c7a907e",
   "metadata": {},
   "source": [
    "## Convert Categorical to Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca66d6be-4eec-4e94-88ba-3f55d9161794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 43 categorical variables\n",
      "there are 39 numerical variables\n"
     ]
    }
   ],
   "source": [
    "# list of categorical and numerical variables\n",
    "cat_cols = df_train.select_dtypes(include = ['object']).columns\n",
    "num_cols = df_train.select_dtypes(include = ['int64', 'float64']).columns\n",
    "print('there are ' + str(len(cat_cols)) + ' categorical variables')\n",
    "print('there are ' + str(len(num_cols)) + ' numerical variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3419b510-ebd1-4a6c-80ab-179711c4becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to the categorical columns\n",
    "df_encoded = pd.get_dummies(df_train, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d999cd1d-e7e8-4bc9-88a1-7a9b7af960e5",
   "metadata": {},
   "source": [
    "Now we can train the model on all variables (except GarageYrBlt for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "febaac90-daa8-4552-b173-c2a27d480467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and response vars\n",
    "# dropping GarageYrBlt because idk what to do with missing values\n",
    "X = df_encoded.drop(columns = ['SalePrice', 'LogSalePrice', 'GarageYrBlt', 'Id'])\n",
    "y = df_encoded['LogSalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a3c5d50-bbf1-48a0-97ba-d304b8e97561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  ...  \\\n",
       "0   1          60         65.0     8450            7  ...   \n",
       "1   2          20         80.0     9600            6  ...   \n",
       "2   3          60         68.0    11250            7  ...   \n",
       "3   4          70         60.0     9550            7  ...   \n",
       "4   5          60         84.0    14260            8  ...   \n",
       "\n",
       "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
       "0                  False                 False                 False   \n",
       "1                  False                 False                 False   \n",
       "2                  False                 False                 False   \n",
       "3                  False                 False                 False   \n",
       "4                  False                 False                 False   \n",
       "\n",
       "   SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                  True                  False  \n",
       "1                  True                  False  \n",
       "2                  True                  False  \n",
       "3                 False                  False  \n",
       "4                  True                  False  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbf0df-782e-40f2-8c45-3638550bf4de",
   "metadata": {},
   "source": [
    "## All Features\n",
    "\n",
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "034d036c-f121-4da7-8be8-e001254ab0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal of project is measured in RMSE\n",
    "# Define a custom RMSE scoring function\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0e0936-bd59-45d7-85a3-13fbfcc0b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [-0.01573318 -0.06884912 -0.01225426 -0.03227351 -0.0733995  -0.02126471\n",
      " -0.05969498 -0.0286174  -0.01812929 -0.05999656]\n",
      "Mean RMSE Score: -0.03902125104956101\n"
     ]
    }
   ],
   "source": [
    "# Create a LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create a 10-fold cross-validation object\n",
    "kf = KFold(n_splits=10 , shuffle=True, random_state=42) # excluding some parameters\n",
    "\n",
    "# Perform cross-validation\n",
    "# scores = cross_val_score(model, X, y, cv=kf, scoring=make_scorer(rmse_scorer, greater_is_better=False))\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-Validation RMSE Scores:\", scores)\n",
    "print(\"Mean RMSE Score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfa32c1c-a05e-423c-a396-d1f541b1aef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 258)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d6ab1-9ce2-4289-a3ef-233aafea9cc6",
   "metadata": {},
   "source": [
    "## CV Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea5772e-8160-4310-b3b5-b36ce9b4f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [-0.13736449 -0.16212022 -0.113248   -0.14067342 -0.17257835 -0.15974991\n",
      " -0.1697204  -0.12815163 -0.14345947 -0.0960964 ]\n",
      "Mean RMSE Score: -0.14231622821773068\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a 10-fold cross-validation object\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(rf_model, X, y, cv=kf, scoring=make_scorer(rmse_scorer, greater_is_better=False))\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(\"Cross-Validation RMSE Scores:\", cross_val_scores)\n",
    "print(\"Mean RMSE Score:\", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab342f-bd6b-430a-836f-bd9dd762dc0c",
   "metadata": {},
   "source": [
    "## Backward Stepping Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8df38d-ee58-46a1-88f4-e451357316bc",
   "metadata": {},
   "source": [
    "## Linear Model Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bf6751c-7c94-47c4-b08a-1c31639ed144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>LogSalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "      <td>12.072541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "      <td>12.254863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "      <td>12.493130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "      <td>11.864462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "      <td>11.901583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea  ... YrSold SaleType  \\\n",
       "0        1          60       RL         65.0     8450  ...   2008       WD   \n",
       "1        2          20       RL         80.0     9600  ...   2007       WD   \n",
       "2        3          60       RL         68.0    11250  ...   2008       WD   \n",
       "3        4          70       RL         60.0     9550  ...   2006       WD   \n",
       "4        5          60       RL         84.0    14260  ...   2008       WD   \n",
       "...    ...         ...      ...          ...      ...  ...    ...      ...   \n",
       "1455  1456          60       RL         62.0     7917  ...   2007       WD   \n",
       "1456  1457          20       RL         85.0    13175  ...   2010       WD   \n",
       "1457  1458          70       RL         66.0     9042  ...   2010       WD   \n",
       "1458  1459          20       RL         68.0     9717  ...   2010       WD   \n",
       "1459  1460          20       RL         75.0     9937  ...   2008       WD   \n",
       "\n",
       "     SaleCondition SalePrice LogSalePrice  \n",
       "0           Normal    208500    12.247694  \n",
       "1           Normal    181500    12.109011  \n",
       "2           Normal    223500    12.317167  \n",
       "3          Abnorml    140000    11.849398  \n",
       "4           Normal    250000    12.429216  \n",
       "...            ...       ...          ...  \n",
       "1455        Normal    175000    12.072541  \n",
       "1456        Normal    210000    12.254863  \n",
       "1457        Normal    266500    12.493130  \n",
       "1458        Normal    142125    11.864462  \n",
       "1459        Normal    147500    11.901583  \n",
       "\n",
       "[1460 rows x 82 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f578527-6c1e-477a-9ec7-aeeedbdcc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 23\n"
     ]
    }
   ],
   "source": [
    "min_features_to_select = 5  # Minimum number of features to consider\n",
    "# model_type = LinearRegression()\n",
    "model_type = RandomForestRegressor(random_state=42)\n",
    "# model_type = Lasso(alpha = 0.05)\n",
    "\n",
    "cv = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=model_type,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=make_scorer(rmse_scorer, greater_is_better=False),\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=1,\n",
    ")\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba39dab0-71d8-4e10-b5b9-7ca03dcb0e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_scores = len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Negative RMSE\")\n",
    "plt.errorbar(\n",
    "    range(min_features_to_select, n_scores + min_features_to_select),\n",
    "    rfecv.cv_results_[\"mean_test_score\"],\n",
    "    #yerr=rfecv.cv_results_[\"std_test_score\"],\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "# ax = plt.gca()\n",
    "# ax.set_ylim([-10, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae445cb2-c67e-410f-9f60-d6e057ce6bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16560338, -0.16163015, -0.15853396, -0.15479485, -0.15126468,\n",
       "       -0.14622849, -0.14419717, -0.14185194, -0.14208788, -0.14230925,\n",
       "       -0.14301208, -0.14174956, -0.14264168, -0.14318387, -0.1424759 ,\n",
       "       -0.14193466, -0.14182664, -0.1413694 , -0.14078377, -0.14154418,\n",
       "       -0.14198861, -0.14160613, -0.14208442, -0.14157419, -0.14149654,\n",
       "       -0.14229445, -0.14230051, -0.14163434, -0.14203071, -0.14200128,\n",
       "       -0.14217429, -0.14219421, -0.14180872, -0.14204794, -0.14202489,\n",
       "       -0.1412694 , -0.14258745, -0.14243043, -0.14178831, -0.14212936,\n",
       "       -0.14185601, -0.14200807, -0.14231547, -0.14192899, -0.14188663,\n",
       "       -0.14199062, -0.14217892, -0.14205405, -0.14196857, -0.14222724,\n",
       "       -0.14200734, -0.1419972 , -0.14203571, -0.14156579, -0.14134049,\n",
       "       -0.14139157, -0.1417698 , -0.14124809, -0.14172889, -0.14115213,\n",
       "       -0.14216362, -0.1419136 , -0.14186818, -0.14163812, -0.14114404,\n",
       "       -0.14166844, -0.14125227, -0.14162768, -0.14163805, -0.14156069,\n",
       "       -0.14155848, -0.14125483, -0.14195642, -0.14121776, -0.1416865 ,\n",
       "       -0.14171421, -0.14152686, -0.14117635, -0.14165964, -0.14163919,\n",
       "       -0.14139983, -0.14146261, -0.1413498 , -0.14148145, -0.14140071,\n",
       "       -0.14133519, -0.14137868, -0.14147609, -0.14113654, -0.14154813,\n",
       "       -0.14112014, -0.14119413, -0.14109593, -0.1413409 , -0.14161031,\n",
       "       -0.14141221, -0.1411154 , -0.14104429, -0.141613  , -0.14211489,\n",
       "       -0.14112208, -0.14107711, -0.14145152, -0.14097058, -0.1411496 ,\n",
       "       -0.14127833, -0.14108569, -0.14084205, -0.14136142, -0.14119815,\n",
       "       -0.14139139, -0.14128431, -0.14145093, -0.14148689, -0.14116421,\n",
       "       -0.14140078, -0.14122722, -0.14148413, -0.1410976 , -0.14168514,\n",
       "       -0.14124981, -0.14192641, -0.14220477, -0.14119539, -0.1411024 ,\n",
       "       -0.14153768, -0.14187158, -0.1417907 , -0.14197402, -0.14167093,\n",
       "       -0.14185368, -0.14142957, -0.14169447, -0.14168831, -0.14178896,\n",
       "       -0.14162107, -0.141901  , -0.14149782, -0.14131678, -0.1415809 ,\n",
       "       -0.14185429, -0.14182919, -0.1416558 , -0.14171925, -0.14154337,\n",
       "       -0.14194494, -0.14130453, -0.14176725, -0.14153916, -0.14141476,\n",
       "       -0.14184721, -0.14188291, -0.14165144, -0.14195715, -0.14144795,\n",
       "       -0.14109351, -0.14203748, -0.14209972, -0.14168648, -0.14120965,\n",
       "       -0.14226547, -0.14142343, -0.14138461, -0.14205004, -0.14150121,\n",
       "       -0.14193008, -0.14162446, -0.14190675, -0.14221243, -0.1412837 ,\n",
       "       -0.14182482, -0.14213864, -0.14207359, -0.14189323, -0.14190132,\n",
       "       -0.14174129, -0.1420682 , -0.14134606, -0.14159439, -0.14140107,\n",
       "       -0.14164573, -0.14171988, -0.1416537 , -0.1420108 , -0.14110315,\n",
       "       -0.14155561, -0.14140801, -0.1414689 , -0.14169909, -0.14155927,\n",
       "       -0.1413892 , -0.14161596, -0.14186092, -0.14149405, -0.14223376,\n",
       "       -0.14159742, -0.14171878, -0.14220244, -0.14199162, -0.1417807 ,\n",
       "       -0.14191573, -0.1416252 , -0.14167614, -0.14175125, -0.14144199,\n",
       "       -0.14172308, -0.14167384, -0.14126483, -0.1414818 , -0.1414063 ,\n",
       "       -0.14173663, -0.14141748, -0.14189638, -0.14215813, -0.14167946,\n",
       "       -0.14166903, -0.14189968, -0.14144872, -0.14163926, -0.14214132,\n",
       "       -0.1411239 , -0.14169531, -0.14166263, -0.14189458, -0.14188485,\n",
       "       -0.14211985, -0.14175493, -0.14145994, -0.14138786, -0.14170443,\n",
       "       -0.1422126 , -0.14151775, -0.14189498, -0.14186053, -0.14152492,\n",
       "       -0.14202357, -0.14207787, -0.14179151, -0.1413899 , -0.14159314,\n",
       "       -0.1416845 , -0.14214962, -0.14152515, -0.14161347, -0.1417407 ,\n",
       "       -0.14174377, -0.14212018, -0.14166062, -0.14174124, -0.14162757,\n",
       "       -0.14172769, -0.14214573, -0.14185398, -0.1416937 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ca9ba5-fb18-4519-890d-d52ca62571c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfecv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrfecv\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfecv' is not defined"
     ]
    }
   ],
   "source": [
    "rfecv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7eb4e-c7d7-4755-bea1-11bb7d31d228",
   "metadata": {},
   "source": [
    "## Autogluon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ce124-1f7d-4382-8beb-0dc42d185bec",
   "metadata": {},
   "source": [
    "First just see what happens with absolutely no treatment of anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd0763c9-5a71-41bd-9b66-56c53b85345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../data/raw/train.csv | Columns = 81 / 81 | Rows = 1460 -> 1460\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d991ad0f-544d-4321-8022-500bf3db5b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea  ... MoSold YrSold SaleType  \\\n",
       "0   1          60       RL         65.0     8450  ...      2   2008       WD   \n",
       "1   2          20       RL         80.0     9600  ...      5   2007       WD   \n",
       "2   3          60       RL         68.0    11250  ...      9   2008       WD   \n",
       "3   4          70       RL         60.0     9550  ...      2   2006       WD   \n",
       "4   5          60       RL         84.0    14260  ...     12   2008       WD   \n",
       "\n",
       "  SaleCondition SalePrice  \n",
       "0        Normal    208500  \n",
       "1        Normal    181500  \n",
       "2        Normal    223500  \n",
       "3       Abnorml    140000  \n",
       "4        Normal    250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d8e486-7780-4933-aed0-c2ab2f47b6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "755158a6-4d6d-4783-aec8-307a271a2c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015137/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015137/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.42 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (12.991753427493052, 10.596634733096073, 11.99881, 0.37896)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2482.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['Utilities', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 33 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 41 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 37 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 31 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  6 | ['Street', 'Heating', 'CentralAir', 'BsmtHalfBath', 'HalfBath', ...]\n",
      "\t1.3s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2583\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2718\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1222\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1199\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.14\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1217\t = Validation score   (-root_mean_squared_error)\n",
      "\t66.31s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1308\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1254\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1441\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1036\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1558\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1003\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 77.89s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015137/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015255/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015255/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.42 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.1260306447518, 11.198214720130528, 12.07048, 0.39333)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2526.8 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 7 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['Street', 'Utilities']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['PoolQC']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['PoolQC']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 37 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 31 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  6 | ['Condition2', 'CentralAir', 'BsmtHalfBath', 'KitchenAbvGr', 'PoolArea', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.81s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2675\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2458\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1551\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1465\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1319\t = Validation score   (-root_mean_squared_error)\n",
      "\t148.44s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1494\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1219\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.138\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1317\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1689\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1085\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 156.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015255/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015532/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015532/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.41 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (12.988040814744458, 11.002099841204238, 12.02751, 0.42593)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2508.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['Utilities', 'Condition2', '3SsnPorch', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 32 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 38 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 29 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['Street', 'CentralAir', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr']\n",
      "\t0.6s = Fit runtime\n",
      "\t75 features in original data used to generate 75 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.3521\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.3466\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1633\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.163646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.165\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1769\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1926\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.83s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1905\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1733\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1568\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1379\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.24s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1772\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.132\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.82s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015532/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015549/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015549/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.40 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.226723392728571, 10.460242108190519, 12.02675, 0.42724)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2491.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 9 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['Utilities', 'LowQualFinSF', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 32 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 41 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 36 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 28 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  9 | ['Street', 'LandSlope', 'Heating', 'CentralAir', 'BsmtHalfBath', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t76 features in original data used to generate 76 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.3177\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.3163\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1832\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1822\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.2057\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.2089\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.09s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.207\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1714\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2478\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1739\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.94s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.2281\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1587\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.35s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015549/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015607/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015607/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.39 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.858998997563564, 12.02662, 0.45592)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2496.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['Street', 'Utilities', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 33 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 38 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 32 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Condition2', 'CentralAir', 'KitchenAbvGr']\n",
      "\t0.6s = Fit runtime\n",
      "\t76 features in original data used to generate 76 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.62s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2986\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.3073\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1749\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1652\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1978\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.2163\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.2295\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1636\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.188\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.2109\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1928\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.192898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1472\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 31.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015607/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015639/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015639/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.38 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.275827535915461, 10.932981961904135, 12.04805, 0.36031)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2455.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 10 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Utilities']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['PoolQC']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['PoolQC']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 41 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 36 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 30 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  9 | ['Street', 'Condition2', 'RoofMatl', 'ExterCond', 'CentralAir', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t78 features in original data used to generate 78 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.68s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2422\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2395\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1316\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1434\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.156\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1347\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.61s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1618\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1305\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1493\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1398\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.141685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1417\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1204\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 27.3s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015639/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015706/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015706/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.37 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.323926946863102, 10.47194980911048, 11.98914, 0.38947)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2466.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['Street', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 33 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 41 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'Utilities', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 36 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 33 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['Utilities', 'LandSlope', 'RoofMatl', 'CentralAir', 'MiscFeature']\n",
      "\t0.6s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.3722\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.362\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.2133\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.214605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2353\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.2411\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.2283\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.21s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.2369\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1586\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2406\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.2366\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.19859\n",
      "[2000]\tvalid_set's rmse: 0.198358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1984\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1542\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 38.65s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015706/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015745/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015745/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.35 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.229567991666638, 11.002099841204238, 11.98778, 0.3738)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2486.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['Utilities', 'Condition2', 'PoolArea', 'PoolQC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 33 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 35 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 30 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Street', 'LandSlope', 'RoofStyle', 'CentralAir', 'LowQualFinSF', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t76 features in original data used to generate 76 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2916\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2862\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.2254\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.2186\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.2381\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.2173\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.52s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.2275\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1896\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2208\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.181\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.236919\n",
      "[2000]\tvalid_set's rmse: 0.236785\n",
      "[3000]\tvalid_set's rmse: 0.236777\n",
      "[4000]\tvalid_set's rmse: 0.236777\n",
      "[5000]\tvalid_set's rmse: 0.236777\n",
      "[6000]\tvalid_set's rmse: 0.236777\n",
      "[7000]\tvalid_set's rmse: 0.236777\n",
      "[8000]\tvalid_set's rmse: 0.236777\n",
      "[9000]\tvalid_set's rmse: 0.236777\n",
      "[10000]\tvalid_set's rmse: 0.236777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2368\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.49s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.179\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 20.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015745/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015807/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015807/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.33 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.521139497361697, 11.133128103610641, 12.06901, 0.37773)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2518.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Utilities']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 42 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 30 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  6 | ['Street', 'CentralAir', 'LowQualFinSF', 'BsmtHalfBath', 'KitchenAbvGr', ...]\n",
      "\t0.6s = Fit runtime\n",
      "\t79 features in original data used to generate 79 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.65s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2739\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.3265\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1867\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1897\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.2438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1993\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.2431\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-0.2938\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2094\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1607\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.229\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1578\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 11.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015807/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_015818/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_015818/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.32 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.053013299269535, 10.868568448579715, 11.99637, 0.40336)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2496.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['Street', 'Utilities', 'Condition2']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 38 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 31 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['RoofMatl', 'CentralAir', 'BsmtFullBath', 'BsmtHalfBath', 'KitchenAbvGr']\n",
      "\t0.6s = Fit runtime\n",
      "\t77 features in original data used to generate 77 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.62s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.2425\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.2306\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1447\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.169\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.1429\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.168\t = Validation score   (-root_mean_squared_error)\n",
      "\t196.25s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1503\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.1144\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1821\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.0999\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.37s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.124664\n",
      "[2000]\tvalid_set's rmse: 0.124652\n",
      "[3000]\tvalid_set's rmse: 0.124652\n",
      "[4000]\tvalid_set's rmse: 0.124652\n",
      "[5000]\tvalid_set's rmse: 0.124652\n",
      "[6000]\tvalid_set's rmse: 0.124652\n",
      "[7000]\tvalid_set's rmse: 0.124652\n",
      "[8000]\tvalid_set's rmse: 0.124652\n",
      "[9000]\tvalid_set's rmse: 0.124652\n",
      "[10000]\tvalid_set's rmse: 0.124652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1247\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.087\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 210.26s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_015818/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean is -0.08651569308481755\n"
     ]
    }
   ],
   "source": [
    "# CV of raw data, no fixin'\n",
    "\n",
    "# import data\n",
    "rawTrain = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "# convert SalePrice to log\n",
    "rawTrain['SalePrice'] = np.log(rawTrain['SalePrice'])\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Calculate the number of samples and the size of each fold\n",
    "num_samples = len(rawTrain)\n",
    "fold_size = num_samples // num_folds\n",
    "\n",
    "# Initialize lists to store the train and test data\n",
    "rmse_list = []\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold in range(num_folds):\n",
    "    # Calculate the start and end indices for the test set\n",
    "    start = fold * fold_size\n",
    "    end = (fold + 1) * fold_size if fold < num_folds - 1 else num_samples\n",
    "\n",
    "    # Use the current fold for testing and the rest for training\n",
    "    tempTest = rawTrain.iloc[start:end, :]  # Slice the DataFrame\n",
    "    tempTrain = pd.concat([rawTrain.iloc[:start, :], rawTrain.iloc[end:, :]])  # Concatenate DataFrames\n",
    "\n",
    "    # convert to Tabular Datasets\n",
    "    tempTest = TabularDataset(tempTest)\n",
    "    tempTrain = TabularDataset(tempTrain)\n",
    "\n",
    "    # fit predictor\n",
    "    tempPredictor = TabularPredictor(label='SalePrice').fit(tempTrain)\n",
    "\n",
    "    # find RMSE of logs\n",
    "    rmse = tempPredictor.evaluate(tempTest, silent=True)['root_mean_squared_error']\n",
    "    \n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# find CV mean of rmse\n",
    "print('CV mean is ' + str(sum(rmse_list) / len(rmse_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f151dd-f2a7-42c0-9b35-f435299d534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting to re-use the trained models\n",
    "\n",
    "myPred = TabularPredictor.load(path = 'AutogluonModels/ag-20231104_015137')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1ab538-b988-4707-8fad-9de708a55eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -0.07618667965781836,\n",
       " 'mean_squared_error': -0.005804410157283033,\n",
       " 'mean_absolute_error': -0.04284989944983148,\n",
       " 'r2': 0.9593045798390804,\n",
       " 'pearsonr': 0.981439348476447,\n",
       " 'median_absolute_error': -0.026794163151611095}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "rawTrain = pd.read_csv('../data/raw/train.csv')\n",
    "\n",
    "# convert SalePrice to log\n",
    "rawTrain['SalePrice'] = np.log(rawTrain['SalePrice'])\n",
    "\n",
    "myTest = TabularDataset(rawTrain.iloc[:146,:])\n",
    "myPred.evaluate(myTest, silent = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1b4c49-93e1-43b1-9c06-76fe9d5705ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean is -0.08651569308481755\n"
     ]
    }
   ],
   "source": [
    "# rechecking CV (models saved in files, must load)\n",
    "path_list = [\n",
    "    'ag-20231104_015137',\n",
    "    'ag-20231104_015255',\n",
    "    'ag-20231104_015532',\n",
    "    'ag-20231104_015549',\n",
    "    'ag-20231104_015607',\n",
    "    'ag-20231104_015639',\n",
    "    'ag-20231104_015706',\n",
    "    'ag-20231104_015745',\n",
    "    'ag-20231104_015807',\n",
    "    'ag-20231104_015818'\n",
    "]\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Calculate the number of samples and the size of each fold\n",
    "num_samples = len(rawTrain)\n",
    "fold_size = num_samples // num_folds\n",
    "\n",
    "# Initialize lists to store the train and test data\n",
    "rmse_list = []\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold in range(num_folds):\n",
    "    # Calculate the start and end indices for the test set\n",
    "    start = fold * fold_size\n",
    "    end = (fold + 1) * fold_size if fold < num_folds - 1 else num_samples\n",
    "\n",
    "    # get test data\n",
    "    myTest = TabularDataset(rawTrain.iloc[start:end,:])\n",
    "\n",
    "    # Load predictor\n",
    "    myPath = 'AutogluonModels/' + path_list[fold]\n",
    "    myPred = TabularPredictor.load(path = myPath)\n",
    "\n",
    "    # evaluate predictor on test data\n",
    "    rmse = myPred.evaluate(myTest, silent = True)['root_mean_squared_error']\n",
    "    \n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "# find CV mean of rmse\n",
    "print('CV mean is ' + str(sum(rmse_list) / len(rmse_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe4c38e-0a14-4b90-9724-6212a9c66c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.07618667965781836,\n",
       " -0.06236001709453796,\n",
       " -0.07094164376511249,\n",
       " -0.09975584200406108,\n",
       " -0.07775805295525264,\n",
       " -0.06411676801919394,\n",
       " -0.08210614977221033,\n",
       " -0.09029345587155786,\n",
       " -0.18313131662799462,\n",
       " -0.05850700508043615]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c03ebc7e-ad8f-48b0-b5b8-7dceff30dcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>LogSalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "      <td>12.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>...</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "      <td>12.109011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "      <td>12.317167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "      <td>11.849398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "      <td>12.429216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea  ... YrSold SaleType  \\\n",
       "0   1          60       RL         65.0     8450  ...   2008       WD   \n",
       "1   2          20       RL         80.0     9600  ...   2007       WD   \n",
       "2   3          60       RL         68.0    11250  ...   2008       WD   \n",
       "3   4          70       RL         60.0     9550  ...   2006       WD   \n",
       "4   5          60       RL         84.0    14260  ...   2008       WD   \n",
       "\n",
       "  SaleCondition SalePrice LogSalePrice  \n",
       "0        Normal    208500    12.247694  \n",
       "1        Normal    181500    12.109011  \n",
       "2        Normal    223500    12.317167  \n",
       "3       Abnorml    140000    11.849398  \n",
       "4        Normal    250000    12.429216  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f43e05e-c68b-41c3-b5b8-27baa2c1d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits for CV\n",
    "\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "\n",
    "# Calculate the number of samples and the size of each fold\n",
    "num_samples = len(X)\n",
    "fold_size = num_samples // num_folds\n",
    "\n",
    "# Initialize lists to store the train and test data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Convert the pandas Series to a numpy array\n",
    "# y = y.values\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold in range(num_folds):\n",
    "    # Calculate the start and end indices for the test set\n",
    "    start = fold * fold_size\n",
    "    end = (fold + 1) * fold_size if fold < num_folds - 1 else num_samples\n",
    "\n",
    "    # Use the current fold for testing and the rest for training\n",
    "    test_X = X.iloc[start:end, :]  # Slice the DataFrame\n",
    "    test_y = y.iloc[start:end]\n",
    "    train_X = pd.concat([X.iloc[:start, :], X.iloc[end:, :]])  # Concatenate DataFrames\n",
    "    train_y = pd.concat([y[:start], y[end:]])\n",
    "\n",
    "    train_data.append((train_X, train_y))\n",
    "    test_data.append((test_X, test_y))\n",
    "\n",
    "# Now you have the train and test data for each fold in the train_data and test_data lists, with X as a pandas DataFrame and y as a pandas Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70bfeb3a-0aa3-4f02-b350-4ce12e5e669b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231103_231823/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231103_231823/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.41 GB / 250.69 GB (7.3%)\n",
      "Train Data Rows:    1460\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (755000, 34900, 180921.19589, 79442.50288)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2797.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.06 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.6s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.52 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.67s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1168, Val Rows: 292\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/Users/cameronthieme/house_env/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "\t-52278.8213\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-51314.2734\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 27505.1\n",
      "[2000]\tvalid_set's rmse: 27240.4\n",
      "[3000]\tvalid_set's rmse: 27201.5\n",
      "[4000]\tvalid_set's rmse: 27197.3\n",
      "[5000]\tvalid_set's rmse: 27197.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-27196.7065\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 29499.8\n",
      "[2000]\tvalid_set's rmse: 28896.4\n",
      "[3000]\tvalid_set's rmse: 28752.1\n",
      "[4000]\tvalid_set's rmse: 28705.7\n",
      "[5000]\tvalid_set's rmse: 28695.2\n",
      "[6000]\tvalid_set's rmse: 28693\n",
      "[7000]\tvalid_set's rmse: 28692.5\n",
      "[8000]\tvalid_set's rmse: 28692.3\n",
      "[9000]\tvalid_set's rmse: 28692.3\n",
      "[10000]\tvalid_set's rmse: 28692.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-28692.2871\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.54s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32782.873\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.9s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-28465.6966\t = Validation score   (-root_mean_squared_error)\n",
      "\t203.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-32047.6167\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-34153.0592\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.28s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-27778.2437\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-35377.4685\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 32134.9\n",
      "[2000]\tvalid_set's rmse: 32087.8\n",
      "[3000]\tvalid_set's rmse: 32084.2\n",
      "[4000]\tvalid_set's rmse: 32084.2\n",
      "[5000]\tvalid_set's rmse: 32084.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-32084.1712\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.79s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-26322.571\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 286.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231103_231823/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='SalePrice').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75f853f5-08e2-48e4-9707-ab2a2b525614",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../data/raw/test.csv | Columns = 80 / 80 | Rows = 1459 -> 1459\n",
      "WARNING: Int features without null values at train time contain null values at inference time! Imputing nulls to 0. To avoid this, pass the features as floats during fit!\n",
      "WARNING: Int features with nulls: ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SalePrice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SalePrice'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_data \u001b[38;5;241m=\u001b[39m TabularDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/raw/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1725\u001b[0m, in \u001b[0;36mTabularPredictor.evaluate\u001b[0;34m(self, data, model, decision_threshold, silent, auxiliary_metrics, detailed_report)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1723\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_predictions(\n\u001b[0;32m-> 1725\u001b[0m     y_true\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m   1726\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m   1727\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1728\u001b[0m     decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold,\n\u001b[1;32m   1729\u001b[0m     silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m   1730\u001b[0m     auxiliary_metrics\u001b[38;5;241m=\u001b[39mauxiliary_metrics,\n\u001b[1;32m   1731\u001b[0m     detailed_report\u001b[38;5;241m=\u001b[39mdetailed_report,\n\u001b[1;32m   1732\u001b[0m )\n",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/house_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SalePrice'"
     ]
    }
   ],
   "source": [
    "test_data = TabularDataset('../data/raw/test.csv')\n",
    "\n",
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5263b7ff-ae2e-4792-898f-d24587534989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>...</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>...</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>...</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea  ... MiscVal MoSold  \\\n",
       "0     1461          20       RH         80.0    11622  ...       0      6   \n",
       "1     1462          20       RL         81.0    14267  ...   12500      6   \n",
       "2     1463          60       RL         74.0    13830  ...       0      3   \n",
       "3     1464          60       RL         78.0     9978  ...       0      6   \n",
       "4     1465         120       RL         43.0     5005  ...       0      1   \n",
       "...    ...         ...      ...          ...      ...  ...     ...    ...   \n",
       "1454  2915         160       RM         21.0     1936  ...       0      6   \n",
       "1455  2916         160       RM         21.0     1894  ...       0      4   \n",
       "1456  2917          20       RL        160.0    20000  ...       0      9   \n",
       "1457  2918          85       RL         62.0    10441  ...     700      7   \n",
       "1458  2919          60       RL         74.0     9627  ...       0     11   \n",
       "\n",
       "     YrSold SaleType SaleCondition  \n",
       "0      2010       WD        Normal  \n",
       "1      2010       WD        Normal  \n",
       "2      2010       WD        Normal  \n",
       "3      2010       WD        Normal  \n",
       "4      2010       WD        Normal  \n",
       "...     ...      ...           ...  \n",
       "1454   2006       WD        Normal  \n",
       "1455   2006       WD       Abnorml  \n",
       "1456   2006       WD       Abnorml  \n",
       "1457   2006       WD        Normal  \n",
       "1458   2006       WD        Normal  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fbb2388-51a4-4246-a23e-7d3d706da5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "myTrain = df_train.iloc[0:1200,:]\n",
    "myTest = df_train.iloc[1200:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "831150ea-ac5b-4df4-afc2-9eb7d78c4857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t4/35cvrsfn4_ngynfyw4c2sf100000gn/T/ipykernel_11231/128144678.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  myTrain['SalePrice'] = np.log(myTrain['SalePrice'])\n",
      "/var/folders/t4/35cvrsfn4_ngynfyw4c2sf100000gn/T/ipykernel_11231/128144678.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  myTest['SalePrice'] = np.log(myTest['SalePrice'])\n"
     ]
    }
   ],
   "source": [
    "myTrain['SalePrice'] = np.log(myTrain['SalePrice'])\n",
    "myTest['SalePrice'] = np.log(myTest['SalePrice'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccde6bae-e219-4251-9a6f-824d380b82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTab = TabularDataset(myTrain)\n",
    "testTab = TabularDataset(myTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08fdde46-a0ce-45dc-b756-ef93d00464d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231104_002047/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231104_002047/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Aug 22 20:17:10 PDT 2022; root:xnu-8020.140.49~2/RELEASE_X86_64\n",
      "Disk Space Avail:   18.17 GB / 250.69 GB (7.2%)\n",
      "Train Data Rows:    1200\n",
      "Train Data Columns: 80\n",
      "Label Column: SalePrice\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (13.534473028231162, 10.460242108190519, 12.02486, 0.40356)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2389.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.52 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])    : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('object', []) : 43 | ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 40 | ['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig', ...]\n",
      "\t\t('float', [])     :  3 | ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "\t\t('int', [])       : 34 | ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['Street', 'Utilities', 'CentralAir']\n",
      "\t0.8s = Fit runtime\n",
      "\t80 features in original data used to generate 80 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 960, Val Rows: 240\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/Users/cameronthieme/house_env/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "\t-0.233\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-0.228\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.1348\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.1457\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.16\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.1394\t = Validation score   (-root_mean_squared_error)\n",
      "\t74.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.1563\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.164\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.1479\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.94s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.1447\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.09s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.1572\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.9s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.1322\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 99.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231104_002047/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='SalePrice').fit(trainTab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25b507d2-8620-4946-a302-167aa992732e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1304236244855546"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(testTab, silent=True)['root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a894a-92a5-4577-87b1-1651c3581690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house_env",
   "language": "python",
   "name": "house_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
