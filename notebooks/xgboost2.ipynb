{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d894b3-8b6e-4fc3-a163-6399d2c360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc47deb-9612-4b35-97b2-7764f061ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_test = pd.read_csv('../data/raw/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe89b06-9cf8-4af6-9ec0-3b24c72b5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert target variable to log\n",
    "# log conversion normalizes data (also is where we measure RMSE)\n",
    "df_train['SalePrice']= np.log(df_train['SalePrice'])\n",
    "# there is no SalePrice variable for test (only Kaggle has)\n",
    "\n",
    "# drop 'Id' column as it is useless\n",
    "df_train = df_train.drop(columns = ['Id'])\n",
    "df_test = df_test.drop(columns = ['Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70668898-a522-45f2-a051-2695b8b55bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NaN\n",
    "\n",
    "# create imputer \n",
    "my_imputer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# impute column by column\n",
    "for col in df_train.columns:\n",
    "    df_train[col] = my_imputer.fit_transform(df_train[[col]]).ravel()\n",
    "    if col == 'SalePrice': # doesn't exist in test, skip\n",
    "        continue\n",
    "    df_test[col] = my_imputer.fit_transform(df_test[[col]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db34c27b-2315-4d49-ab5e-c16fcb42160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameronthieme/Documents/JimmyProject/house_values/myEnv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [0, 5, 15, 16, 30, 31, 41] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding\n",
    "# apply same encoding to test as training\n",
    "# this drops some data from test because we have extra categories there\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown = 'ignore')  # drop='first' to avoid multicollinearity\n",
    "\n",
    "# train encoder on training data\n",
    "encoder.fit(df_train[categorical_cols])\n",
    "\n",
    "# Fit and transform the encoder on the categorical columns in df_train\n",
    "df_train_encoded = pd.DataFrame(encoder.transform(df_train[categorical_cols]))\n",
    "df_train_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "df_train = pd.concat([df_train, df_train_encoded], axis=1)\n",
    "\n",
    "# Drop the original categorical columns as they are no longer needed\n",
    "df_train = df_train.drop(categorical_cols, axis=1)\n",
    "\n",
    "# Now, perform the same one-hot encoding for df_test\n",
    "# Note: Use transform instead of fit_transform to apply the same encoding as df_train\n",
    "df_test_encoded = pd.DataFrame(encoder.transform(df_test[categorical_cols]))\n",
    "df_test_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "df_test = pd.concat([df_test, df_test_encoded], axis=1)\n",
    "\n",
    "# Drop the original categorical columns as they are no longer needed\n",
    "df_test = df_test.drop(categorical_cols, axis=1)\n",
    "\n",
    "# Now, df_train and df_test have the same columns after one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76bf9d1-06e9-4b85-9e1d-29e00436ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_xgboost(df_train):\n",
    "    # target and features\n",
    "    X = df_train.drop(columns = ['SalePrice'])\n",
    "    y = df_train['SalePrice']\n",
    "\n",
    "    # Create an XGBoost regressor model\n",
    "    xg_reg = xgb.XGBRegressor(\n",
    "        objective ='reg:squarederror',\n",
    "        colsample_bytree = 0.3,\n",
    "        learning_rate = 0.1,\n",
    "        max_depth = 5,\n",
    "        alpha = 10,\n",
    "        n_estimators = 10\n",
    "    )\n",
    "\n",
    "    # train and return model\n",
    "    xg_reg.fit(X,y)\n",
    "    return xg_reg\n",
    "\n",
    "xg_reg = get_trained_xgboost(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e457b1a8-4a43-457f-acff-324b0a699653",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.exp(xg_reg.predict(df_test)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "668fc73b-195e-41bc-813a-4d30151e4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 1461\n",
    "# Create a DataFrame with the reshaped array and the desired index\n",
    "df_pred = pd.DataFrame(y_pred, \n",
    "                      index=np.arange(start_idx, start_idx + len(y_pred)),\n",
    "                      columns=['SalePrice'])\n",
    "df_pred.index.name = 'Id'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_pred.to_csv('your_file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1906a4b0-dd51-45ab-94fd-3dbdc51ac33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f5af9c-26f9-4bd0-bcc0-20408f1fa24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_array = np.array([1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9dd8879-c925-43de-bbb9-4bfbe30d8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86c1fb-45cb-45ad-8cfd-07bc0f6d09e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
